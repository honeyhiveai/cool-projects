{
    "nbformat": 4,
    "nbformat_minor": 2,
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n# \"Tracing LlamaIndex Pipelines\"\n## \"Get started by tracing your LlamaIndex queries with HoneyHive.\"\nThis notebook is a companion to this [guide](https://docs.honeyhive.ai/quickstart/llamaindex). You can also [Open in Colab](https://colab.research.google.com/github/honeyhiveai/honeyhive-cookbook/blob/master/docs/notebooks/quickstart_llamaindex.ipynb)### Introduction\n\nIn the following example, we are going to walk through how to log your LlamaIndex runs to HoneyHive for benchmarking and sharing. For a complete overview of LlamaIndex tracing in HoneyHive, you can refer to our [LlamaIndex Tracing](/logging-llamaindex) guide.\n\n### Get API key\n\nAfter signing up on the app, you can find your API key in the [Settings](https://app.honeyhive.ai/settings/account) page under Account.\n\n### Install the SDK\n\nWe currently support a native Python SDK. For other languages, we encourage using HTTP request libraries to send requests.\n\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "source": [
                "pip install honeyhive -q\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "hhai"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n\n### Trace your LlamaIndex queries\n\nIf you haven't already done so, then the first thing you will need to do is <a href=\"/projects#create-a-new-project\">create a HoneyHive project</a>.\n\nOnce you have created a HoneyHive project, you can now start tracing your LlamaIndex pipeline.\n\n1. **Initializing HoneyHive tracer:** First, let's start by initializing the HoneyHive tracer. See below.\n\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "source": [
                "import honeyhive\nimport os\nfrom honeyhive.utils.llamaindex_tracer import HoneyHiveLlamaIndexTracer\n\nos.environ[\"HONEYHIVE_API_KEY\"] = \"YOUR_HONEYHIVE_API_KEY\"\n\ntracer = HoneyHiveLlamaIndexTracer(\n    project=\"PG Q&A Bot\",  # necessary field: specify which project within HoneyHive\n    name=\"Paul Graham Q&A\",  # optional field: name of the chain/agent you are running\n    source=\"staging\",  # optional field: source (to separate production & staging environments)\n    user_properties={  # optional field: specify user properties for whom this was ran\n        \"user_id\": \"sd8298bxjn0s\",\n        \"user_account\": \"Acme\"                                 \n        \"user_country\": \"United States\",\n        \"user_subscriptiontier\": \"enterprise\"\n    }\n)\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "hhai"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n\n2. **Defining LlamaIndex pipeline:** Next, let's define our LlamaIndex pipeline and initialize the service context with the HoneyHive tracer. See below.\n\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "source": [
                "from llama_index import VectorStoreIndex, SimpleWebPageReader, ServiceContext\nfrom llama_index.callbacks import CallbackManager, LlamaDebugHandler\nimport openai\n\nopenai.api_key = \"YOUR_OPENAI_API_KEY\"\n\n# Initialize the service context with the HoneyHive tracer\ncallback_manager = CallbackManager([tracer])\nservice_context = ServiceContext.from_defaults(callback_manager=callback_manager)\n\ndocuments = SimpleWebPageReader(html_to_text=True).load_data(\n    [\"http://paulgraham.com/worked.html\"]\n)\n\n# Pass the service_context to the index that you will query\nindex = VectorStoreIndex.from_documents(\n    documents, service_context=service_context\n)\n\nquery_engine = index.as_query_engine()\nresponse = query_engine.query(\"What did the author do growing up?\")\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "hhai"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n\nYou can now view this trace from within the HoneyHive platform by clicking on **Datasets** in the sidebar and then **Traces**.\n![Trace](/images/trace_screenshot.png)\n\n### Log user feedback for this session\n\nNow that you\u2019ve logged a request in HoneyHive, let\u2019s try logging user feedback and ground truth labels associated with this session.\n\nUsing the `session_id` that is returned, you can send arbitrary feedback to HoneyHive using the feedback endpoint.\n\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "source": [
                "honeyhive.sessions.feedback(\n    session_id = tracer.session_id,\n    feedback = {\n        \"accepted\": True,\n        \"saved\": True,\n        \"regenerated\": False,\n        \"edited\": False\n    }\n)\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "hhai"
                    ]
                }
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    }
}