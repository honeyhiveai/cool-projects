{
    "nbformat": 4,
    "nbformat_minor": 2,
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n# \"Tracing Custom Pipelines (Python)\"\n## \"Get started by tracing your custom python pipeline with HoneyHive.\"\nThis notebook is a companion to this [guide](https://docs.honeyhive.ai/quickstart/hhaitracer) <a target=\"_blank\" href=\"https://github.com/honeyhiveai/honeyhive-cookbook/blob/master/docs/notebooks/honeyhive-cookbook/docs/notebooks/quickstart_hhaitracer.ipynb\">\n  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>### Introduction\n\nOur Python SDK allows you to trace your custom pipelines with per-event visibility. This allows you to monitor your pipeline's performance and log user feedback and ground truth labels associated with each step.\n\nFor an in-depth overview of how trace data is structured, please see our [Logging Overview](/logging-overview) page.\n\n### Setup HoneyHive and get your API key\n\nIf you haven't already done so, then the first thing you will need to do is <a href=\"/projects#create-a-new-project\">create a HoneyHive project</a>.\n\nAfter creating the project, you can find your API key in the [Settings](https://app.honeyhive.ai/settings/account) page under Account.\n\nOnce you have created a HoneyHive project and got your API keys, you can now start tracing your custom pipeline.\n\n### Install the SDK\n\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "source": [
                "!pip install -U honeyhive\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "hhai"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n\n### Initializing HoneyHive tracer\n\nFirst, let's start by initializing the HoneyHive tracer.\n\nTo initialize the tracer, we need to provide 2 necessary parameters:\n1. `project` - the name of the HoneyHive project you want to log to\n2. `name` - the name of the pipeline you are tracing\n\nWe also provide 2 optional parameters:\n1. `source` - the source of the pipeline (e.g. \"production\" or \"testing\")\n2. `user_properties` - a dictionary of user properties for whom this pipeline was ran\n\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "source": [
                "import os\nfrom honeyhive.utils.tracer import HoneyHiveTracer\n\nos.environ[\"HONEYHIVE_API_KEY\"] = \"YOUR_HONEYHIVE_API_KEY\"\n\ntracer = HoneyHiveTracer(\n    project=\"Sandbox - Email Writer\",  # necessary field: specify which project within HoneyHive\n    name=\"Paul Graham Q&A\",            # optional field: name of the chain/agent you are running\n    source=\"testing\",                  # optional field: source (to separate production & testing in monitoring)\n    user_properties={                  # optional field: specify user properties for whom this was ran\n        \"user_id\": \"1234\",\n        \"user_country\": \"US\"\n    }\n)\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "hhai"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n\n### Tracing a model completion call\n\nNext, let's trace a model completion call.\n\nWe place the code we want to trace within a `with` block. This automatically calculates latency, metadata, inputs and outputs of the call.\n\nTo trace the model completion call via `tracer.model`, we need to provide 2 necessary parameters:\n- `event_name` - the name of the event you are tracing\n- `input` - the input to the event\n\nOn top of these, we also provide 2 optional parameters:\n- `config` - a dictionary of configuration parameters for the model\n- `description` - a description of what the model is doing\n\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "source": [
                "with tracer.model(\n    event_name=\"Email Writer\",\n    description=\"Generate an email response based on context provided\",\n    config={\n        \"model\": \"gpt-3.5-turbo\",\n        \"chat_template\": YOUR_TEMPLATE_HERE\n    }\n) as model_call:\n    openai_response = openai.ChatCompletion.create(...)\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "hhai"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n\nYou can access the `event_id` for this model completion call via `model_call.event_id`.\n\n### Tracing other arbitrary events\n\nTracing vector database queries, API calls, and other arbitrary events is very similar to tracing model completion calls.\n\nTo trace the vector database query via `tracer.tool`, we need to provide 1 necessary parameter:\n- `event_name` - the name of the event you are tracing\n\nOn top of these, we also provide 2 optional parameters:\n- `config` - a dictionary of configuration parameters for the tool\n- `description` - a description of what the tool is doing\n\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "source": [
                "with tracer.tool(\n    event_name=\"Context Provider\",\n    description=\"Get context for the email response\",\n    config={\n        \"index\": \"quickstart\",\n        \"provider\": \"pinecone\",\n        \"chunk_size\": 512\n    }\n) as pinecone_call:\n    pinecone_response = pinecone.query(...)\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "hhai"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n\n### Logging user feedback for the session\n\nNow that you\u2019ve logged a trace in HoneyHive, let\u2019s try logging user feedback and ground truth labels associated with this session.\n\nUsing the `session_id` that is specified on the tracer, you can send arbitrary feedback to HoneyHive using the feedback endpoint. If `event_id` is not specified, feedback is set for the entire session. \n\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "source": [
                "honeyhive.sessions.feedback(\n    session_id = tracer.session_id,\n    feedback = {\n       \"accepted\": True,\n       \"edited\": False\n    }\n)\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "hhai"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n\n### Logging user feedback for a particular event\n\nIn case you need to provide feedback for a specific event, you can do so by specifying the `event_id` as follows:\n\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "source": [
                "honeyhive.sessions.feedback(\n    session_id = tracer.session_id,\n    event_id = model_call.event_id,\n    ground_truth = \"INSERT_GROUND_TRUTH_LABEL\",\n    feedback = {\n       \"accepted\": False\n    }\n)\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "hhai"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n\n### Finish and view trace\n\nFinally, we need to finish tracing the pipeline. This will send the trace to HoneyHive.\n\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "source": [
                "tracer.end_session()\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "hhai"
                    ]
                }
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    }
}